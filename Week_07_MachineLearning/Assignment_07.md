## 1. 分类和回归问题的主要区别
### 1.1 输出数据的类型
- 分类输出的数据类型是离散型数据，也就是分类的标签。<br>
  比如通过学生学习情况预测考试是否通过，这里的预测结果是考试通过或者不通过，这2种离散数据。
- 回归输出的数据类型是连续型数据。<br>
  比如通过学习时间预测学生的考试分数，这里的预测结果分数，是连续型数据。
### 1.2 想通过机器学习算法得到什么
- 分类算法得到的是一个决策面，用于对数据集中的数据进行分类。
- 回归算法得到的是一个最优拟合线，这条线可以最好的接近数据集中的各个点。
### 1.3 对模型的评估标准
- 在分类算法中，通常会使用正确率作为指标，也就是预测结果中分类正确数据占总数据的比例。
- 在回归算法中，用决定系数R平方来评估模型的好坏。R平方表示有多少百分比的Y波动被回归线描述。
----
## 2. 模型评价指标
### 2.1 概念图
![](https://github.com/pchen12567/picture_store/blob/master/AI_For_NLP/validation.png?raw=true)
### 2.2 相关概念
- **真正例TP** = True Positive，预测值是1，真实值是1，被正确分类的正例样本
- **假正例FP** = False Positive，预测值是1，但真实值是0
- **真反例TN** = True Negative，预测值是0，真实值是0
- **假反例FN** = False Negative，预测值是0，但真实值是1
- **TPR(Recall，召回率）**：TP/(TP+FN)，表示检测率
- **Precision（精确率）**：TP/（TP+FP）
- **FPR**： FP/（TN+FP），在所有实际值是0的样本中，被错误地预测为1的比例
- 此外还有ROC曲线（AUC值就是ROC曲线下面的面积），PR曲线，混淆矩阵和F1值。
----
## 3. 过拟合
### 3.1 什么是过拟合
过拟合就是训练出来的模型在训练集上表现很好，但是在测试集上表现较差的一种现象。
### 3.2 造成过拟合的原因
- 数据存在噪声；
- 训练数据不足，有限的训练数据；
- 训练模型过度，模型复杂度太高。
### 3.3 如何防止过拟合
- 获取更多数据，增加训练数据可以有限的避免过拟合；
- 数据增强
- 简化模型，特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间；
- 正则化，常用的有 L1、L2 正则。而且 L1正则还可以自动进行特征选择；
- 如果有正则项则可以考虑增大正则项参数；
- 交叉检验，通过交叉检验得到较优的模型参数；
- Bagging，将多个弱学习器Bagging 一下效果会好很多，比如随机森林等。
----
## 4. 欠拟合
### 4.1 什么是欠拟合
欠拟合就是模型没有很好地捕捉到数据特征，不能够很好地拟合数据。
### 4.2 造成欠拟合的原因
- 模型复杂度过低
- 训练误差大
### 4.3 如何防止欠拟合
- 增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间;
- 尝试非线性模型，比如核SVM 、决策树、DNN等模型;
- 如果有正则项可以较小正则项参数;
- Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等.
